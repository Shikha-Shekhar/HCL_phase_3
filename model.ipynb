{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Developement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing relevant Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import math\n",
    "import numpy as np\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.framework import ops\n",
    "from sklearn import preprocessing\n",
    "# Load the TensorBoard notebook extension\n",
    "%reload_ext tensorboard\n",
    "import datetime\n",
    "import os\n",
    "# Clear any logs from previous runs\n",
    "!rm -rf ./logs/ \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Pre-processed datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "npz=np.load('Audiobooks_data_train.npz')\n",
    "train_inputs=npz['inputs'].astype(np.float)\n",
    "train_targets=npz['targets'].astype(np.int)\n",
    "\n",
    "npz=np.load('Audiobooks_data_validation.npz')\n",
    "validation_inputs=npz['inputs'].astype(np.float)\n",
    "validation_targets=npz['targets'].astype(np.int)\n",
    "\n",
    "npz=np.load('Audiobooks_data_test.npz')\n",
    "test_inputs=npz['inputs'].astype(np.float)\n",
    "test_targets=npz['targets'].astype(np.int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining Model Structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining input_size,output_size, batch_size amd epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 10\n",
    "output_size = 2\n",
    "hidden_layer_size=64\n",
    "# set the batch size\n",
    "batch_size = 100\n",
    "\n",
    "\n",
    "# set a maximum number of training epochs\n",
    "max_epochs = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outlining Model ( 2 hidden layers with 64 hidden units each)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define how the model will look like\n",
    "model = tf.keras.Sequential([\n",
    "    # tf.keras.layers.Dense is basically implementing: output = activation(dot(input, weight) + bias)\n",
    "    tf.keras.layers.Dense(hidden_layer_size, activation='relu'),    # 1st hidden layer\n",
    "    tf.keras.layers.Dropout(0.7),                                   #Regularization (Dropout)\n",
    "    tf.keras.layers.Dense(hidden_layer_size, activation='relu'), # 2nd hidden layer\n",
    "    tf.keras.layers.Dropout(0.7),                                    #Regularization (Dropout)\n",
    "    # the final layer is no different, we just make sure to activate it with softmax\n",
    "   \n",
    "    tf.keras.layers.Dense(output_size, activation='softmax') # output layer\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choosing Optimization Algorithm, defining cost function and choosing metrics for model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Defining Callbacks to Visualize, Monitor and Improve our Deep Learning Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weights of the best model according to val_accuracy metrics will be saved in best_modek.hdf5 file)\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(\"best_model.hdf5\",monitor='val_accuracy', \n",
    "                                                verbose=1, save_best_only=True, mode='max')\n",
    "# early stopping\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(patience=4)\n",
    "\n",
    "# visualization\n",
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting model (First : without any callback function, Second: early stopping callback, Third : saving weights of the best model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3579 samples, validate on 447 samples\n",
      "Epoch 1/100\n",
      "3579/3579 - 7s - loss: 0.7820 - accuracy: 0.5706 - val_loss: 0.5272 - val_accuracy: 0.8725\n",
      "Epoch 2/100\n",
      "3579/3579 - 1s - loss: 0.6409 - accuracy: 0.6720 - val_loss: 0.4497 - val_accuracy: 0.8770\n",
      "Epoch 3/100\n",
      "3579/3579 - 0s - loss: 0.5515 - accuracy: 0.7332 - val_loss: 0.3982 - val_accuracy: 0.8770\n",
      "Epoch 4/100\n",
      "3579/3579 - 0s - loss: 0.5173 - accuracy: 0.7804 - val_loss: 0.3705 - val_accuracy: 0.8747\n",
      "Epoch 5/100\n",
      "3579/3579 - 0s - loss: 0.4782 - accuracy: 0.8089 - val_loss: 0.3527 - val_accuracy: 0.8770\n",
      "Epoch 6/100\n",
      "3579/3579 - 0s - loss: 0.4605 - accuracy: 0.8187 - val_loss: 0.3385 - val_accuracy: 0.8770\n",
      "Epoch 7/100\n",
      "3579/3579 - 0s - loss: 0.4344 - accuracy: 0.8298 - val_loss: 0.3310 - val_accuracy: 0.8814\n",
      "Epoch 8/100\n",
      "3579/3579 - 0s - loss: 0.4183 - accuracy: 0.8379 - val_loss: 0.3245 - val_accuracy: 0.8837\n",
      "Epoch 9/100\n",
      "3579/3579 - 0s - loss: 0.4091 - accuracy: 0.8458 - val_loss: 0.3187 - val_accuracy: 0.8859\n",
      "Epoch 10/100\n",
      "3579/3579 - 0s - loss: 0.4089 - accuracy: 0.8491 - val_loss: 0.3151 - val_accuracy: 0.8881\n",
      "Epoch 11/100\n",
      "3579/3579 - 0s - loss: 0.3890 - accuracy: 0.8539 - val_loss: 0.3087 - val_accuracy: 0.8881\n",
      "Epoch 12/100\n",
      "3579/3579 - 0s - loss: 0.3860 - accuracy: 0.8631 - val_loss: 0.3066 - val_accuracy: 0.8904\n",
      "Epoch 13/100\n",
      "3579/3579 - 0s - loss: 0.3748 - accuracy: 0.8583 - val_loss: 0.3042 - val_accuracy: 0.8926\n",
      "Epoch 14/100\n",
      "3579/3579 - 0s - loss: 0.3746 - accuracy: 0.8670 - val_loss: 0.3005 - val_accuracy: 0.8904\n",
      "Epoch 15/100\n",
      "3579/3579 - 0s - loss: 0.3612 - accuracy: 0.8715 - val_loss: 0.2982 - val_accuracy: 0.8949\n",
      "Epoch 16/100\n",
      "3579/3579 - 0s - loss: 0.3616 - accuracy: 0.8712 - val_loss: 0.2947 - val_accuracy: 0.8949\n",
      "Epoch 17/100\n",
      "3579/3579 - 0s - loss: 0.3556 - accuracy: 0.8776 - val_loss: 0.2918 - val_accuracy: 0.8949\n",
      "Epoch 18/100\n",
      "3579/3579 - 0s - loss: 0.3545 - accuracy: 0.8787 - val_loss: 0.2888 - val_accuracy: 0.8993\n",
      "Epoch 19/100\n",
      "3579/3579 - 0s - loss: 0.3413 - accuracy: 0.8776 - val_loss: 0.2871 - val_accuracy: 0.9016\n",
      "Epoch 20/100\n",
      "3579/3579 - 0s - loss: 0.3373 - accuracy: 0.8776 - val_loss: 0.2824 - val_accuracy: 0.8993\n",
      "Epoch 21/100\n",
      "3579/3579 - 0s - loss: 0.3336 - accuracy: 0.8804 - val_loss: 0.2806 - val_accuracy: 0.9016\n",
      "Epoch 22/100\n",
      "3579/3579 - 0s - loss: 0.3272 - accuracy: 0.8801 - val_loss: 0.2782 - val_accuracy: 0.9038\n",
      "Epoch 23/100\n",
      "3579/3579 - 0s - loss: 0.3188 - accuracy: 0.8854 - val_loss: 0.2741 - val_accuracy: 0.8993\n",
      "Epoch 24/100\n",
      "3579/3579 - 0s - loss: 0.3226 - accuracy: 0.8801 - val_loss: 0.2722 - val_accuracy: 0.9083\n",
      "Epoch 25/100\n",
      "3579/3579 - 0s - loss: 0.3208 - accuracy: 0.8854 - val_loss: 0.2704 - val_accuracy: 0.9060\n",
      "Epoch 26/100\n",
      "3579/3579 - 0s - loss: 0.3142 - accuracy: 0.8849 - val_loss: 0.2703 - val_accuracy: 0.9083\n",
      "Epoch 27/100\n",
      "3579/3579 - 0s - loss: 0.3200 - accuracy: 0.8857 - val_loss: 0.2676 - val_accuracy: 0.9105\n",
      "Epoch 28/100\n",
      "3579/3579 - 0s - loss: 0.3216 - accuracy: 0.8894 - val_loss: 0.2654 - val_accuracy: 0.9105\n",
      "Epoch 29/100\n",
      "3579/3579 - 0s - loss: 0.3111 - accuracy: 0.8838 - val_loss: 0.2640 - val_accuracy: 0.9105\n",
      "Epoch 30/100\n",
      "3579/3579 - 0s - loss: 0.3083 - accuracy: 0.8902 - val_loss: 0.2627 - val_accuracy: 0.9060\n",
      "Epoch 31/100\n",
      "3579/3579 - 0s - loss: 0.3054 - accuracy: 0.8919 - val_loss: 0.2615 - val_accuracy: 0.9083\n",
      "Epoch 32/100\n",
      "3579/3579 - 0s - loss: 0.3072 - accuracy: 0.8921 - val_loss: 0.2590 - val_accuracy: 0.9083\n",
      "Epoch 33/100\n",
      "3579/3579 - 0s - loss: 0.3060 - accuracy: 0.8944 - val_loss: 0.2579 - val_accuracy: 0.9105\n",
      "Epoch 34/100\n",
      "3579/3579 - 0s - loss: 0.3024 - accuracy: 0.8938 - val_loss: 0.2579 - val_accuracy: 0.9105\n",
      "Epoch 35/100\n",
      "3579/3579 - 0s - loss: 0.2946 - accuracy: 0.8924 - val_loss: 0.2562 - val_accuracy: 0.9105\n",
      "Epoch 36/100\n",
      "3579/3579 - 0s - loss: 0.2902 - accuracy: 0.8933 - val_loss: 0.2510 - val_accuracy: 0.9128\n",
      "Epoch 37/100\n",
      "3579/3579 - 0s - loss: 0.2926 - accuracy: 0.8986 - val_loss: 0.2518 - val_accuracy: 0.9105\n",
      "Epoch 38/100\n",
      "3579/3579 - 0s - loss: 0.2905 - accuracy: 0.8935 - val_loss: 0.2531 - val_accuracy: 0.9128\n",
      "Epoch 39/100\n",
      "3579/3579 - 0s - loss: 0.2893 - accuracy: 0.8933 - val_loss: 0.2505 - val_accuracy: 0.9083\n",
      "Epoch 40/100\n",
      "3579/3579 - 0s - loss: 0.2853 - accuracy: 0.8958 - val_loss: 0.2477 - val_accuracy: 0.9083\n",
      "Epoch 41/100\n",
      "3579/3579 - 0s - loss: 0.2849 - accuracy: 0.8991 - val_loss: 0.2458 - val_accuracy: 0.9150\n",
      "Epoch 42/100\n",
      "3579/3579 - 1s - loss: 0.2861 - accuracy: 0.8958 - val_loss: 0.2448 - val_accuracy: 0.9150\n",
      "Epoch 43/100\n",
      "3579/3579 - 0s - loss: 0.2842 - accuracy: 0.9008 - val_loss: 0.2433 - val_accuracy: 0.9150\n",
      "Epoch 44/100\n",
      "3579/3579 - 0s - loss: 0.2833 - accuracy: 0.8997 - val_loss: 0.2435 - val_accuracy: 0.9172\n",
      "Epoch 45/100\n",
      "3579/3579 - 0s - loss: 0.2748 - accuracy: 0.8955 - val_loss: 0.2418 - val_accuracy: 0.9150\n",
      "Epoch 46/100\n",
      "3579/3579 - 0s - loss: 0.2774 - accuracy: 0.8986 - val_loss: 0.2400 - val_accuracy: 0.9150\n",
      "Epoch 47/100\n",
      "3579/3579 - 0s - loss: 0.2766 - accuracy: 0.9005 - val_loss: 0.2426 - val_accuracy: 0.9150\n",
      "Epoch 48/100\n",
      "3579/3579 - 0s - loss: 0.2737 - accuracy: 0.9033 - val_loss: 0.2378 - val_accuracy: 0.9195\n",
      "Epoch 49/100\n",
      "3579/3579 - 0s - loss: 0.2797 - accuracy: 0.9005 - val_loss: 0.2396 - val_accuracy: 0.9195\n",
      "Epoch 50/100\n",
      "3579/3579 - 0s - loss: 0.2766 - accuracy: 0.9036 - val_loss: 0.2375 - val_accuracy: 0.9217\n",
      "Epoch 51/100\n",
      "3579/3579 - 0s - loss: 0.2766 - accuracy: 0.8991 - val_loss: 0.2374 - val_accuracy: 0.9195\n",
      "Epoch 52/100\n",
      "3579/3579 - 0s - loss: 0.2693 - accuracy: 0.9044 - val_loss: 0.2395 - val_accuracy: 0.9195\n",
      "Epoch 53/100\n",
      "3579/3579 - 0s - loss: 0.2676 - accuracy: 0.9016 - val_loss: 0.2363 - val_accuracy: 0.9217\n",
      "Epoch 54/100\n",
      "3579/3579 - 0s - loss: 0.2634 - accuracy: 0.9067 - val_loss: 0.2367 - val_accuracy: 0.9217\n",
      "Epoch 55/100\n",
      "3579/3579 - 0s - loss: 0.2650 - accuracy: 0.9067 - val_loss: 0.2326 - val_accuracy: 0.9217\n",
      "Epoch 56/100\n",
      "3579/3579 - 0s - loss: 0.2694 - accuracy: 0.9028 - val_loss: 0.2335 - val_accuracy: 0.9195\n",
      "Epoch 57/100\n",
      "3579/3579 - 0s - loss: 0.2678 - accuracy: 0.9033 - val_loss: 0.2354 - val_accuracy: 0.9217\n",
      "Epoch 58/100\n",
      "3579/3579 - 1s - loss: 0.2627 - accuracy: 0.9061 - val_loss: 0.2329 - val_accuracy: 0.9195\n",
      "Epoch 59/100\n",
      "3579/3579 - 0s - loss: 0.2679 - accuracy: 0.9030 - val_loss: 0.2323 - val_accuracy: 0.9195\n",
      "Epoch 60/100\n",
      "3579/3579 - 0s - loss: 0.2595 - accuracy: 0.9081 - val_loss: 0.2341 - val_accuracy: 0.9217\n",
      "Epoch 61/100\n",
      "3579/3579 - 0s - loss: 0.2603 - accuracy: 0.9047 - val_loss: 0.2312 - val_accuracy: 0.9217\n",
      "Epoch 62/100\n",
      "3579/3579 - 0s - loss: 0.2609 - accuracy: 0.9061 - val_loss: 0.2321 - val_accuracy: 0.9217\n",
      "Epoch 63/100\n",
      "3579/3579 - 0s - loss: 0.2615 - accuracy: 0.9061 - val_loss: 0.2338 - val_accuracy: 0.9217\n",
      "Epoch 64/100\n",
      "3579/3579 - 1s - loss: 0.2590 - accuracy: 0.9047 - val_loss: 0.2352 - val_accuracy: 0.9217\n",
      "Epoch 65/100\n",
      "3579/3579 - 0s - loss: 0.2602 - accuracy: 0.9078 - val_loss: 0.2347 - val_accuracy: 0.9217\n",
      "Epoch 66/100\n",
      "3579/3579 - 0s - loss: 0.2607 - accuracy: 0.9058 - val_loss: 0.2314 - val_accuracy: 0.9217\n",
      "Epoch 67/100\n",
      "3579/3579 - 0s - loss: 0.2580 - accuracy: 0.9039 - val_loss: 0.2318 - val_accuracy: 0.9217\n",
      "Epoch 68/100\n",
      "3579/3579 - 0s - loss: 0.2575 - accuracy: 0.9039 - val_loss: 0.2303 - val_accuracy: 0.9217\n",
      "Epoch 69/100\n",
      "3579/3579 - 0s - loss: 0.2605 - accuracy: 0.9075 - val_loss: 0.2318 - val_accuracy: 0.9217\n",
      "Epoch 70/100\n",
      "3579/3579 - 1s - loss: 0.2574 - accuracy: 0.9092 - val_loss: 0.2303 - val_accuracy: 0.9217\n",
      "Epoch 71/100\n",
      "3579/3579 - 0s - loss: 0.2609 - accuracy: 0.9044 - val_loss: 0.2330 - val_accuracy: 0.9195\n",
      "Epoch 72/100\n",
      "3579/3579 - 1s - loss: 0.2571 - accuracy: 0.9058 - val_loss: 0.2302 - val_accuracy: 0.9217\n",
      "Epoch 73/100\n",
      "3579/3579 - 1s - loss: 0.2633 - accuracy: 0.9067 - val_loss: 0.2299 - val_accuracy: 0.9217\n",
      "Epoch 74/100\n",
      "3579/3579 - 0s - loss: 0.2476 - accuracy: 0.9081 - val_loss: 0.2274 - val_accuracy: 0.9217\n",
      "Epoch 75/100\n",
      "3579/3579 - 0s - loss: 0.2579 - accuracy: 0.9078 - val_loss: 0.2294 - val_accuracy: 0.9217\n",
      "Epoch 76/100\n",
      "3579/3579 - 0s - loss: 0.2599 - accuracy: 0.9092 - val_loss: 0.2314 - val_accuracy: 0.9217\n",
      "Epoch 77/100\n",
      "3579/3579 - 0s - loss: 0.2545 - accuracy: 0.9081 - val_loss: 0.2294 - val_accuracy: 0.9217\n",
      "Epoch 78/100\n",
      "3579/3579 - 1s - loss: 0.2628 - accuracy: 0.9033 - val_loss: 0.2333 - val_accuracy: 0.9217\n",
      "Epoch 79/100\n",
      "3579/3579 - 1s - loss: 0.2557 - accuracy: 0.9064 - val_loss: 0.2291 - val_accuracy: 0.9217\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/100\n",
      "3579/3579 - 1s - loss: 0.2525 - accuracy: 0.9086 - val_loss: 0.2296 - val_accuracy: 0.9217\n",
      "Epoch 81/100\n",
      "3579/3579 - 1s - loss: 0.2557 - accuracy: 0.9042 - val_loss: 0.2291 - val_accuracy: 0.9172\n",
      "Epoch 82/100\n",
      "3579/3579 - 1s - loss: 0.2499 - accuracy: 0.9089 - val_loss: 0.2305 - val_accuracy: 0.9217\n",
      "Epoch 83/100\n",
      "3579/3579 - 1s - loss: 0.2481 - accuracy: 0.9072 - val_loss: 0.2281 - val_accuracy: 0.9217\n",
      "Epoch 84/100\n",
      "3579/3579 - 1s - loss: 0.2488 - accuracy: 0.9081 - val_loss: 0.2286 - val_accuracy: 0.9217\n",
      "Epoch 85/100\n",
      "3579/3579 - 1s - loss: 0.2496 - accuracy: 0.9084 - val_loss: 0.2307 - val_accuracy: 0.9217\n",
      "Epoch 86/100\n",
      "3579/3579 - 0s - loss: 0.2522 - accuracy: 0.9103 - val_loss: 0.2276 - val_accuracy: 0.9217\n",
      "Epoch 87/100\n",
      "3579/3579 - 0s - loss: 0.2506 - accuracy: 0.9058 - val_loss: 0.2268 - val_accuracy: 0.9217\n",
      "Epoch 88/100\n",
      "3579/3579 - 0s - loss: 0.2465 - accuracy: 0.9098 - val_loss: 0.2298 - val_accuracy: 0.9195\n",
      "Epoch 89/100\n",
      "3579/3579 - 0s - loss: 0.2480 - accuracy: 0.9086 - val_loss: 0.2278 - val_accuracy: 0.9217\n",
      "Epoch 90/100\n",
      "3579/3579 - 1s - loss: 0.2464 - accuracy: 0.9120 - val_loss: 0.2249 - val_accuracy: 0.9217\n",
      "Epoch 91/100\n",
      "3579/3579 - 0s - loss: 0.2471 - accuracy: 0.9089 - val_loss: 0.2253 - val_accuracy: 0.9217\n",
      "Epoch 92/100\n",
      "3579/3579 - 1s - loss: 0.2473 - accuracy: 0.9092 - val_loss: 0.2279 - val_accuracy: 0.9217\n",
      "Epoch 93/100\n",
      "3579/3579 - 0s - loss: 0.2499 - accuracy: 0.9075 - val_loss: 0.2274 - val_accuracy: 0.9195\n",
      "Epoch 94/100\n",
      "3579/3579 - 0s - loss: 0.2491 - accuracy: 0.9100 - val_loss: 0.2273 - val_accuracy: 0.9195\n",
      "Epoch 95/100\n",
      "3579/3579 - 0s - loss: 0.2526 - accuracy: 0.9084 - val_loss: 0.2302 - val_accuracy: 0.9195\n",
      "Epoch 96/100\n",
      "3579/3579 - 0s - loss: 0.2508 - accuracy: 0.9092 - val_loss: 0.2294 - val_accuracy: 0.9172\n",
      "Epoch 97/100\n",
      "3579/3579 - 1s - loss: 0.2404 - accuracy: 0.9103 - val_loss: 0.2273 - val_accuracy: 0.9150\n",
      "Epoch 98/100\n",
      "3579/3579 - 0s - loss: 0.2496 - accuracy: 0.9050 - val_loss: 0.2283 - val_accuracy: 0.9217\n",
      "Epoch 99/100\n",
      "3579/3579 - 0s - loss: 0.2458 - accuracy: 0.9075 - val_loss: 0.2253 - val_accuracy: 0.9217\n",
      "Epoch 100/100\n",
      "3579/3579 - 0s - loss: 0.2448 - accuracy: 0.9095 - val_loss: 0.2269 - val_accuracy: 0.9217\n"
     ]
    }
   ],
   "source": [
    "size_histories = {}\n",
    "size_histories['First']= model.fit(train_inputs, # train inputs\n",
    "                                  train_targets, # train targets\n",
    "                                  batch_size=batch_size, # batch size\n",
    "                                  epochs=max_epochs, # epochs that we will train for (assuming early stopping doesn't kick in)\n",
    "                                  validation_data=(validation_inputs, validation_targets), # validation data\n",
    "                                  verbose = 2 # making sure we get enough information about the training process\n",
    "                                )  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3579 samples, validate on 447 samples\n",
      "Epoch 1/100\n",
      "3579/3579 - 1s - loss: 0.7800 - accuracy: 0.5599 - val_loss: 0.5447 - val_accuracy: 0.8098\n",
      "Epoch 2/100\n",
      "3579/3579 - 0s - loss: 0.6407 - accuracy: 0.6622 - val_loss: 0.4688 - val_accuracy: 0.8702\n",
      "Epoch 3/100\n",
      "3579/3579 - 0s - loss: 0.5651 - accuracy: 0.7200 - val_loss: 0.4160 - val_accuracy: 0.8770\n",
      "Epoch 4/100\n",
      "3579/3579 - 0s - loss: 0.5065 - accuracy: 0.7751 - val_loss: 0.3723 - val_accuracy: 0.8770\n",
      "Epoch 5/100\n",
      "3579/3579 - 0s - loss: 0.4762 - accuracy: 0.8019 - val_loss: 0.3493 - val_accuracy: 0.8837\n",
      "Epoch 6/100\n",
      "3579/3579 - 0s - loss: 0.4490 - accuracy: 0.8148 - val_loss: 0.3340 - val_accuracy: 0.8881\n",
      "Epoch 7/100\n",
      "3579/3579 - 0s - loss: 0.4343 - accuracy: 0.8321 - val_loss: 0.3276 - val_accuracy: 0.8904\n",
      "Epoch 8/100\n",
      "3579/3579 - 0s - loss: 0.4086 - accuracy: 0.8427 - val_loss: 0.3166 - val_accuracy: 0.8926\n",
      "Epoch 9/100\n",
      "3579/3579 - 0s - loss: 0.3965 - accuracy: 0.8466 - val_loss: 0.3117 - val_accuracy: 0.8971\n",
      "Epoch 10/100\n",
      "3579/3579 - 0s - loss: 0.3924 - accuracy: 0.8502 - val_loss: 0.3068 - val_accuracy: 0.8971\n",
      "Epoch 11/100\n",
      "3579/3579 - 0s - loss: 0.3895 - accuracy: 0.8544 - val_loss: 0.3026 - val_accuracy: 0.8971\n",
      "Epoch 12/100\n",
      "3579/3579 - 1s - loss: 0.3803 - accuracy: 0.8586 - val_loss: 0.2994 - val_accuracy: 0.8971\n",
      "Epoch 13/100\n",
      "3579/3579 - 2s - loss: 0.3765 - accuracy: 0.8695 - val_loss: 0.2958 - val_accuracy: 0.8971\n",
      "Epoch 14/100\n",
      "3579/3579 - 1s - loss: 0.3607 - accuracy: 0.8687 - val_loss: 0.2907 - val_accuracy: 0.8993\n",
      "Epoch 15/100\n",
      "3579/3579 - 0s - loss: 0.3520 - accuracy: 0.8737 - val_loss: 0.2884 - val_accuracy: 0.9016\n",
      "Epoch 16/100\n",
      "3579/3579 - 0s - loss: 0.3502 - accuracy: 0.8759 - val_loss: 0.2862 - val_accuracy: 0.9016\n",
      "Epoch 17/100\n",
      "3579/3579 - 0s - loss: 0.3471 - accuracy: 0.8779 - val_loss: 0.2833 - val_accuracy: 0.9038\n",
      "Epoch 18/100\n",
      "3579/3579 - 0s - loss: 0.3366 - accuracy: 0.8776 - val_loss: 0.2793 - val_accuracy: 0.9083\n",
      "Epoch 19/100\n",
      "3579/3579 - 0s - loss: 0.3238 - accuracy: 0.8846 - val_loss: 0.2746 - val_accuracy: 0.9083\n",
      "Epoch 20/100\n",
      "3579/3579 - 0s - loss: 0.3325 - accuracy: 0.8821 - val_loss: 0.2736 - val_accuracy: 0.9083\n",
      "Epoch 21/100\n",
      "3579/3579 - 0s - loss: 0.3326 - accuracy: 0.8832 - val_loss: 0.2716 - val_accuracy: 0.9083\n",
      "Epoch 22/100\n",
      "3579/3579 - 0s - loss: 0.3239 - accuracy: 0.8840 - val_loss: 0.2684 - val_accuracy: 0.9083\n",
      "Epoch 23/100\n",
      "3579/3579 - 1s - loss: 0.3246 - accuracy: 0.8852 - val_loss: 0.2683 - val_accuracy: 0.9083\n",
      "Epoch 24/100\n",
      "3579/3579 - 1s - loss: 0.3220 - accuracy: 0.8829 - val_loss: 0.2654 - val_accuracy: 0.9083\n",
      "Epoch 25/100\n",
      "3579/3579 - 1s - loss: 0.3144 - accuracy: 0.8899 - val_loss: 0.2655 - val_accuracy: 0.9083\n",
      "Epoch 26/100\n",
      "3579/3579 - 1s - loss: 0.3104 - accuracy: 0.8930 - val_loss: 0.2610 - val_accuracy: 0.9083\n",
      "Epoch 27/100\n",
      "3579/3579 - 1s - loss: 0.3095 - accuracy: 0.8916 - val_loss: 0.2602 - val_accuracy: 0.9105\n",
      "Epoch 28/100\n",
      "3579/3579 - 1s - loss: 0.3051 - accuracy: 0.8885 - val_loss: 0.2574 - val_accuracy: 0.9083\n",
      "Epoch 29/100\n",
      "3579/3579 - 1s - loss: 0.3054 - accuracy: 0.8916 - val_loss: 0.2584 - val_accuracy: 0.9083\n",
      "Epoch 30/100\n",
      "3579/3579 - 0s - loss: 0.3034 - accuracy: 0.8885 - val_loss: 0.2551 - val_accuracy: 0.9083\n",
      "Epoch 31/100\n",
      "3579/3579 - 0s - loss: 0.2953 - accuracy: 0.8949 - val_loss: 0.2514 - val_accuracy: 0.9083\n",
      "Epoch 32/100\n",
      "3579/3579 - 1s - loss: 0.3034 - accuracy: 0.8924 - val_loss: 0.2510 - val_accuracy: 0.9105\n",
      "Epoch 33/100\n",
      "3579/3579 - 0s - loss: 0.2911 - accuracy: 0.8941 - val_loss: 0.2495 - val_accuracy: 0.9105\n",
      "Epoch 34/100\n",
      "3579/3579 - 0s - loss: 0.2936 - accuracy: 0.8930 - val_loss: 0.2470 - val_accuracy: 0.9105\n",
      "Epoch 35/100\n",
      "3579/3579 - 1s - loss: 0.2974 - accuracy: 0.8983 - val_loss: 0.2485 - val_accuracy: 0.9105\n",
      "Epoch 36/100\n",
      "3579/3579 - 0s - loss: 0.2915 - accuracy: 0.8927 - val_loss: 0.2458 - val_accuracy: 0.9105\n",
      "Epoch 37/100\n",
      "3579/3579 - 0s - loss: 0.2924 - accuracy: 0.8933 - val_loss: 0.2468 - val_accuracy: 0.9128\n",
      "Epoch 38/100\n",
      "3579/3579 - 0s - loss: 0.2799 - accuracy: 0.8972 - val_loss: 0.2427 - val_accuracy: 0.9128\n",
      "Epoch 39/100\n",
      "3579/3579 - 0s - loss: 0.2825 - accuracy: 0.8980 - val_loss: 0.2424 - val_accuracy: 0.9150\n",
      "Epoch 40/100\n",
      "3579/3579 - 0s - loss: 0.2862 - accuracy: 0.8966 - val_loss: 0.2425 - val_accuracy: 0.9150\n",
      "Epoch 41/100\n",
      "3579/3579 - 0s - loss: 0.2739 - accuracy: 0.9011 - val_loss: 0.2405 - val_accuracy: 0.9150\n",
      "Epoch 42/100\n",
      "3579/3579 - 0s - loss: 0.2809 - accuracy: 0.8969 - val_loss: 0.2399 - val_accuracy: 0.9172\n",
      "Epoch 43/100\n",
      "3579/3579 - 0s - loss: 0.2757 - accuracy: 0.9000 - val_loss: 0.2393 - val_accuracy: 0.9172\n",
      "Epoch 44/100\n",
      "3579/3579 - 0s - loss: 0.2701 - accuracy: 0.9019 - val_loss: 0.2408 - val_accuracy: 0.9150\n",
      "Epoch 45/100\n",
      "3579/3579 - 0s - loss: 0.2685 - accuracy: 0.8969 - val_loss: 0.2410 - val_accuracy: 0.9150\n",
      "Epoch 46/100\n",
      "3579/3579 - 0s - loss: 0.2746 - accuracy: 0.8986 - val_loss: 0.2394 - val_accuracy: 0.9172\n",
      "Epoch 47/100\n",
      "3579/3579 - 0s - loss: 0.2726 - accuracy: 0.8983 - val_loss: 0.2358 - val_accuracy: 0.9172\n",
      "Epoch 48/100\n",
      "3579/3579 - 0s - loss: 0.2746 - accuracy: 0.9014 - val_loss: 0.2376 - val_accuracy: 0.9195\n",
      "Epoch 49/100\n",
      "3579/3579 - 0s - loss: 0.2725 - accuracy: 0.9003 - val_loss: 0.2404 - val_accuracy: 0.9195\n",
      "Epoch 50/100\n",
      "3579/3579 - 0s - loss: 0.2691 - accuracy: 0.9053 - val_loss: 0.2363 - val_accuracy: 0.9172\n",
      "Epoch 51/100\n",
      "3579/3579 - 0s - loss: 0.2749 - accuracy: 0.9028 - val_loss: 0.2398 - val_accuracy: 0.9217\n"
     ]
    }
   ],
   "source": [
    "size_histories = {}\n",
    "size_histories['second']= model.fit(train_inputs, # train inputs\n",
    "                                  train_targets, # train targets\n",
    "                                  batch_size=batch_size, # batch size\n",
    "                                  epochs=max_epochs, # epochs that we will train for (assuming early stopping doesn't kick in)\n",
    "                                  callbacks=[tensorboard_callback,early_stopping], # early stopping\n",
    "                                  validation_data=(validation_inputs, validation_targets), # validation data\n",
    "                                  verbose = 2 # making sure we get enough information about the training process\n",
    "                                )  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3579 samples, validate on 447 samples\n",
      "Epoch 1/100\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92170\n",
      "3579/3579 - 0s - loss: 0.2514 - accuracy: 0.9084 - val_loss: 0.2317 - val_accuracy: 0.9217\n",
      "Epoch 2/100\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.92170\n",
      "3579/3579 - 1s - loss: 0.2566 - accuracy: 0.9058 - val_loss: 0.2298 - val_accuracy: 0.9195\n",
      "Epoch 3/100\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.92170\n",
      "3579/3579 - 0s - loss: 0.2584 - accuracy: 0.9067 - val_loss: 0.2321 - val_accuracy: 0.9217\n",
      "Epoch 4/100\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.92170\n",
      "3579/3579 - 0s - loss: 0.2588 - accuracy: 0.9061 - val_loss: 0.2290 - val_accuracy: 0.9217\n",
      "Epoch 5/100\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.92170\n",
      "3579/3579 - 0s - loss: 0.2565 - accuracy: 0.9067 - val_loss: 0.2267 - val_accuracy: 0.9217\n",
      "Epoch 6/100\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.92170\n",
      "3579/3579 - 1s - loss: 0.2593 - accuracy: 0.9092 - val_loss: 0.2293 - val_accuracy: 0.9217\n",
      "Epoch 7/100\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.92170\n",
      "3579/3579 - 1s - loss: 0.2595 - accuracy: 0.9070 - val_loss: 0.2291 - val_accuracy: 0.9217\n",
      "Epoch 8/100\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.92170\n",
      "3579/3579 - 0s - loss: 0.2565 - accuracy: 0.9064 - val_loss: 0.2328 - val_accuracy: 0.9217\n",
      "Epoch 9/100\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.92170\n",
      "3579/3579 - 0s - loss: 0.2534 - accuracy: 0.9067 - val_loss: 0.2316 - val_accuracy: 0.9195\n"
     ]
    }
   ],
   "source": [
    "size_histories = {}\n",
    "size_histories['third']= model.fit(train_inputs, # train inputs\n",
    "                                  train_targets, # train targets\n",
    "                                  batch_size=batch_size, # batch size\n",
    "                                  epochs=max_epochs, # epochs that we will train for (assuming early stopping doesn't kick in)\n",
    "                                  callbacks=[tensorboard_callback,early_stopping,checkpoint], # early stopping\n",
    "                                  validation_data=(validation_inputs, validation_targets), # validation data\n",
    "                                  verbose = 2 # making sure we get enough information about the training process\n",
    "                                )  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%tensorboard` not found.\n"
     ]
    }
   ],
   "source": [
    "%tensorboard --logdir logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "448/1 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 2s 5ms/sample - loss: 0.1987 - accuracy: 0.9219\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(test_inputs, test_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test loss: 0.22. Test accuracy: 92.19%\n"
     ]
    }
   ],
   "source": [
    "print('\\nTest loss: {0:.2f}. Test accuracy: {1:.2f}%'.format(test_loss, test_accuracy*100.))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
